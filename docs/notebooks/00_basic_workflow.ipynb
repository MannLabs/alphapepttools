{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example `alphatools` workflow with proteomics data\n",
    "\n",
    "This notebook demonstrates core `alphatools` functionality for proteomics data loading, preprocessing and visualization. \n",
    "\n",
    "Functionalities are intended to be as close to pure python as possible, avoiding closed end-to-end implementations, which is reflected in several design choices: \n",
    "\n",
    "1. AnnData is used in favor of a custom data class to enable interoperability with any other tool from the Scverse.\n",
    "2. matplotlib *Axes* and *Figure* instances are used for visualization, giving the user full autonomy to layer on custom visualizations with searborn, matplotlib, or any other compatible visualization package.\n",
    "3. Statistical and preprocessing functions are standalone and set with strong defaults, meaning that any function can be used outside of the `alphatools` context. \n",
    "\n",
    "### Design choices of `alphatools`:\n",
    "- **Data handling**: `AnnData` was chosen as a data container for two main reasons: 1) For presenting a lightweight, powerful solution to a fundamental challenge with dataframes, which is keeping numerical data and metadata aligned together at all times. Using dataframes, the options are to either include non-numeric metadata columns in the dataframe, complicating data operations, or to add cumbersome multi-level indices and 2) For their compatibility with the Scverse, Scanpy and all associated tools, essentially removing the barrier between proteomics and transcriptomics data analysis and enabling multi-omics analyses. \n",
    "- **Plotting**: Inspired by the [`stylia`] package, we provide a consistent design throughout `alphatools`, aiming to provide a consistent and aesthetically pleasing visual experience for all plots. A core component of this implementation is the fact that `create_figure` returns subplots as an iterable data structure, meaning that once the basic layout of a plot is decided, users simply jump from one plot window to the next and populate each one with figure elements. \n",
    "- **Standardization**: A key consideration of this package is the loading of proteomics data, the biggest painpoint of which is the nonstandard output of various proteomic search enginges. By building on `alphabase`, we handle this complexity early and provide the user with AnnData objects containing either proteins or precursors, which on the one hand can be converted to metadata containing dataframes nearly frictionless by running `df = adata.to_df().join(adata.obs)` and on the other hand are compatible with any foreseeable downstream analysis task.\n",
    "\n",
    "[`stylia`]: https://github.com/ersilia-os/stylia.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example dataset: Alzheimer study\n",
    "\n",
    "We demonstrate `alphatools` functionality on a published dataset by Bader et al. [2], who measured cerebrospinal fluid proteomes in order to discover biomarkers for Alzheimer's disease.\n",
    "\n",
    "[2]: Bader, Jakob M., et al. \"Proteome profiling in cerebrospinal fluid reveals novel biomarkers of Alzheimer's disease.\" Molecular systems biology 16.6 (2020): e9356."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphabase/alphabase/tools/data_downloader.py:4: DeprecationWarning: 'cgi' is deprecated and slated for removal in Python 3.13\n",
      "  import cgi\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "from alphabase.tools.data_downloader import DataShareDownloader\n",
    "\n",
    "from alphatools.io.anndata_factory import AnnDataFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and add the dataset using `alphatools` loaders and AnnData factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/hhd_z4hx3070zw8rlj4c3l940000gn/T/tmpu8qgu1uk/report.parquet does not yet exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/hhd_z4hx3070zw8rlj4c3l940000gn/T/tmpu8qgu1uk/report.parquet successfully downloaded (91.135817527771 MB)\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 7: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m tempfile\u001b[39m.\u001b[39mTemporaryDirectory() \u001b[39mas\u001b[39;00m temp_dir:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     file_path \u001b[39m=\u001b[39m DataShareDownloader(url\u001b[39m=\u001b[39murl, output_dir\u001b[39m=\u001b[39mtemp_dir)\u001b[39m.\u001b[39mdownload()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     factory \u001b[39m=\u001b[39m AnnDataFactory\u001b[39m.\u001b[39;49mfrom_files(file_paths\u001b[39m=\u001b[39;49mfile_path, reader_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdiann\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/mann_labs/_git_repositories/alphatools/src/alphatools/io/anndata_factory.py:128\u001b[0m, in \u001b[0;36mAnnDataFactory.from_files\u001b[0;34m(cls, file_paths, reader_type, intensity_column, protein_id_column, raw_name_column, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m custom_column_mapping:\n\u001b[1;32m    126\u001b[0m     reader\u001b[39m.\u001b[39madd_column_mapping(custom_column_mapping)\n\u001b[0;32m--> 128\u001b[0m psm_df \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mload(file_paths)\n\u001b[1;32m    129\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(psm_df)\n",
      "File \u001b[0;32m~/Documents/mann_labs/_git_repositories/alphabase/alphabase/psm_reader/psm_reader.py:212\u001b[0m, in \u001b[0;36mPSMReaderBase.load\u001b[0;34m(self, _file)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_file, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimport_files(_file)\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimport_file(_file)\n",
      "File \u001b[0;32m~/Documents/mann_labs/_git_repositories/alphabase/alphabase/psm_reader/psm_reader.py:231\u001b[0m, in \u001b[0;36mPSMReaderBase.import_file\u001b[0;34m(self, _file)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport_file\u001b[39m(\u001b[39mself\u001b[39m, _file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    221\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Main entry function of PSM readers.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[39m    Imports a file and processes it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     origin_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_file(_file)\n\u001b[1;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_psm_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(origin_df):\n\u001b[1;32m    236\u001b[0m         \u001b[39m# TODO: think about dropping the 'inplace' pattern here\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/mann_labs/_git_repositories/alphabase/alphabase/psm_reader/psm_reader.py:262\u001b[0m, in \u001b[0;36mPSMReaderBase._load_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_load_file\u001b[39m(\u001b[39mself\u001b[39m, filename: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    257\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load PSM file into a dataframe.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[39m    Different search engines may store PSMs in different ways: tsv, csv, HDF, XML, ...\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    This default implementation works for tsv and csv files and thus covers many readers.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     sep \u001b[39m=\u001b[39m _get_delimiter(filename)\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(filename, sep\u001b[39m=\u001b[39msep, keep_default_na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/mann_labs/_git_repositories/alphabase/alphabase/utils.py:66\u001b[0m, in \u001b[0;36m_get_delimiter\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 66\u001b[0m         line \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mreadline()\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m line:\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 7: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "url = \"https://datashare.biochem.mpg.de/s/Wa9jAJvOJO35D5e/download?path=%2Fpg_matrix%2FBaderEtAl2020%2Fdiann&files=report.parquet\"\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    file_path = DataShareDownloader(url=url, output_dir=temp_dir).download()\n",
    "    factory = AnnDataFactory.from_files(file_paths=file_path, reader_type=\"diann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/2l/hhd_z4hx3070zw8rlj4c3l940000gn/T/tmpvtfripcn/report.parquet'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/var/folders/2l/hhd_z4hx3070zw8rlj4c3l940000gn/T/tmpvtfripcn/report.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the DIANN report from file\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincenthbrennsteiner/Documents/mann_labs/_git_repositories/alphatools/docs/notebooks/00_basic_workflow.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m factory \u001b[39m=\u001b[39m AnnDataFactory\u001b[39m.\u001b[39;49mfrom_files(file_paths\u001b[39m=\u001b[39;49mfile_path, reader_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdiann\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/mann_labs/_git_repositories/alphatools/src/alphatools/io/anndata_factory.py:128\u001b[0m, in \u001b[0;36mAnnDataFactory.from_files\u001b[0;34m(cls, file_paths, reader_type, intensity_column, protein_id_column, raw_name_column, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m custom_column_mapping:\n\u001b[1;32m    126\u001b[0m     reader\u001b[39m.\u001b[39madd_column_mapping(custom_column_mapping)\n\u001b[0;32m--> 128\u001b[0m psm_df \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mload(file_paths)\n\u001b[1;32m    129\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(psm_df)\n",
      "File \u001b[0;32m~/miniconda3/envs/alphaverse/lib/python3.11/site-packages/alphabase/psm_reader/psm_reader.py:208\u001b[0m, in \u001b[0;36mPSMReaderBase.load\u001b[0;34m(self, _file)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_file, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimport_files(_file)\n\u001b[0;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimport_file(_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/alphaverse/lib/python3.11/site-packages/alphabase/psm_reader/psm_reader.py:227\u001b[0m, in \u001b[0;36mPSMReaderBase.import_file\u001b[0;34m(self, _file)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport_file\u001b[39m(\u001b[39mself\u001b[39m, _file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    217\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Main entry function of PSM readers.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[1;32m    219\u001b[0m \u001b[39m    Imports a file and processes it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     origin_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_file(_file)\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_psm_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(origin_df):\n\u001b[1;32m    232\u001b[0m         \u001b[39m# TODO: think about dropping the 'inplace' pattern here\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/alphaverse/lib/python3.11/site-packages/alphabase/psm_reader/psm_reader.py:258\u001b[0m, in \u001b[0;36mPSMReaderBase._load_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_load_file\u001b[39m(\u001b[39mself\u001b[39m, filename: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    253\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load PSM file into a dataframe.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m \u001b[39m    Different search engines may store PSMs in different ways: tsv, csv, HDF, XML, ...\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    This default implementation works for tsv and csv files and thus covers many readers.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     sep \u001b[39m=\u001b[39m _get_delimiter(filename)\n\u001b[1;32m    259\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(filename, sep\u001b[39m=\u001b[39msep, keep_default_na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/alphaverse/lib/python3.11/site-packages/alphabase/utils.py:65\u001b[0m, in \u001b[0;36m_get_delimiter\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     63\u001b[0m     file_path\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_path) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     66\u001b[0m         line \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m line:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/var/folders/2l/hhd_z4hx3070zw8rlj4c3l940000gn/T/tmpvtfripcn/report.parquet'"
     ]
    }
   ],
   "source": [
    "# Load the DIANN report from file\n",
    "factory = AnnDataFactory.from_files(file_paths=file_path, reader_type=\"diann\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphaverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
